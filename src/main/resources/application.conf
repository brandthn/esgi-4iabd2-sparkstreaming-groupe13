taxi {
  producer {
    # Configuration données source
    data {
      # Chemin du fichier CSV : trajets de taxi
      sourceFile = "data/yellow_tripdata_2024-01-preview.csv"
      
      # Nombre de trajets à envoyer par batch
      batchSize = 10
      
      # Intervalle secondes entre l'envoi de chaque batch
      intervalSeconds = 10
    }
    
    # Configuration Kafka
    kafka {
      # Nom du topic Kafka pour les données de taxi
      topic = "yellow-taxi-trips"
      
      # Adresses des brokers Kafka (séparées par des virgules si plusieurs)
      brokers = "kafka:9092"
      
      # Configuration pour visualiser les données envoyées
      debugOutput {
        # Activer la sortie des données pour déboguer
        enabled = true
        
        # Chemin du fichier pour enregistrer les batchs envoyés
        file = "data/debug/sent_batches.txt"
        
        # Afficher également dans la console
        console = true
      }
    }
  }
  
  consumer {
    # Configuration Spark Streaming
    spark {
      # Nom de l'application
      appName = "YellowTaxiTripConsumer"
      
      # Intervalle de batch en secondes
      batchIntervalSeconds = 10
      
      # Nombre de partitions pour les RDDs 
      shufflePartitions = 2
    }
    
    # Configuration Kafka
    kafka {
      # Nom du topic Kafka à consommer
      topic = "yellow-taxi-trips"
      
      # Adresses des brokers Kafka
      brokers = "kafka:9092"
      
      # ID du groupe de consommateurs
      groupId = "yellow-taxi-consumer-group"
    }
    
    # Configuration de la sortie
    output {
      # Activer l'écriture des batchs pour visualisation
      enabled = true
      
      # Dossier où écrire les batchs traités (pour Streamlit)
      directory = "data/processed"
      
      # Format de sortie (parquet, json, csv)
      format = "json"
    }
  }
}